import streamlit as st
from langchain_community.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

# --- OpenAI APIã‚­ãƒ¼ã¯ Streamlit Cloud ã® secrets.toml ã«è¨­å®šã™ã‚‹ ---
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]

# --- LLMè¨­å®šï¼ˆLangChainï¼‰---
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

# --- å°‚é–€å®¶ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šç¾© ---
expert_prompts = {
    "æ „é¤Šå£«": "ã‚ãªãŸã¯ãƒ—ãƒ­ã®æ „é¤Šå£«ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€ç§‘å­¦çš„æ ¹æ‹ ã®ã‚ã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚",
    "ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ": "ã‚ãªãŸã¯ä¸€æµã®ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚è³ªå•ã«å¯¾ã—ã¦ã€è«–ç†çš„ã‹ã¤å®Ÿè·µçš„ãªæˆ¦ç•¥ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚",
    "æ­´å²ç ”ç©¶å®¶": "ã‚ãªãŸã¯æ­´å²ã«ç²¾é€šã—ãŸå°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€æ™‚ä»£èƒŒæ™¯ã‚„äº‹å®Ÿã«åŸºã¥ã„ãŸèª¬æ˜ã‚’ã—ã¦ãã ã•ã„ã€‚",
}

# --- LLMå¿œç­”ç”Ÿæˆé–¢æ•° ---
def generate_response(expert_type, user_input):
    system_message = SystemMessage(content=expert_prompts[expert_type])
    human_message = HumanMessage(content=user_input)
    response = llm([system_message, human_message])
    return response.content

# --- Streamlit UI ---
st.set_page_config(page_title="å°‚é–€å®¶ã«èã„ã¦ã¿ã‚ˆã†ï¼", layout="centered")

st.title("ğŸ§  å°‚é–€å®¶AIãƒãƒ£ãƒƒãƒˆ")
st.markdown("ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒ ã«è³ªå•ã‚’å…¥åŠ›ã—ã€ç›¸è«‡ã—ãŸã„å°‚é–€å®¶ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚LLMãŒãã®å°‚é–€å®¶ã«ãªã‚Šãã£ã¦ãŠç­”ãˆã—ã¾ã™ã€‚")

# --- å°‚é–€å®¶é¸æŠ ---
expert_type = st.radio("ç›¸è«‡ã™ã‚‹å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š", list(expert_prompts.keys()))

# --- è³ªå•å…¥åŠ› ---
user_input = st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=150)

# --- å¿œç­”è¡¨ç¤º ---
if st.button("è³ªå•ã™ã‚‹"):
    if user_input.strip() == "":
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("å°‚é–€å®¶ãŒå›ç­”ä¸­..."):
            answer = generate_response(expert_type, user_input)
        st.success("âœ… å›ç­”çµæœ")
        st.write(answer)
